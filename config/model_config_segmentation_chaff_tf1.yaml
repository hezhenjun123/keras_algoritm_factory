RUN_ENV: aws #{aws, local}
BATCH_SIZE: 4
LEARNING_RATE: 0.0001
EPOCHS: 700
TRAIN_STEPS_PER_EPOCH: -1
VALID_STEPS_PER_EPOCH: -1
DROPOUT: 0
NUM_CLASSES: 2
CHANNEL_LIST: [32, 64, 128, 256]
ACTIVATION: relu
NUM_PLOTS: 5
LOAD_MODEL: false  #if true, Load_Model_Directory must be specified too
LOAD_MODEL_DIRECTORY: null #can be s3 path, hdf5 file format

LOCAL_PARA:
  DIR_OUT: ./out
  DATA_DIR: s3://zoomlion-prod-data/harvester/chaff-content/segmentation/data-v0.3/

AWS_PARA:
  DIR_OUT: /workspace/output/
  DATA_DIR: s3://zoomlion-prod-data/harvester/chaff-content/segmentation/data-v0.3/

DATA_GENERATOR:
  OUTPUT_SHAPE: [512, 512]
  OUTPUT_IMAGE_CHANNELS: 3
  OUTPUT_IMAGE_TYPE: float32
  DROP_REMAINDER: false
  CACHE_DIR: cache
  NUM_PARALLEL_CALLS: 4
  REPEAT: true

TRANSFORM:
  RESIZE: [512, 512]

TRAINING_DATA_INFO:
  TRAIN_CSV_FILE: s3://zoomlion-prod-data/harvester/chaff-content/segmentation/data-v0.3/train.csv
  VALID_CSV_FILE: s3://zoomlion-prod-data/harvester/chaff-content/segmentation/data-v0.3/train.csv
  SPLIT: split
  SPLIT_TRAIN_VAL: train
  SPLIT_VALID_VAL: valid
  SEPARATOR: ','
  IMAGE_PATH: image_path
  SEGMENTATION_PATH: seg_label_path
  LABEL_NAME: label_name
  IMAGE_LEVEL_LABEL: image_level_label


EXPERIMENT:
  EXPERIMENT_NAME: ExperimentSegmentationTF1Unet
  MODEL_NAME: ModelTF1UnetSegmentation
  TRAIN_TRANSFORM: TransformSegmentation
  TRAIN_GENERATOR: GeneratorSegmentation
  VALID_TRANSFORM: # If empty, use TRAIN_TRANSFORM
  VALID_GENERATOR: # If empty, use TRAIN_GENERATOR
